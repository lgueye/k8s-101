# K8S - Deployment, Service, etc.

Préfixez toutes les commandes par ``sudo``.

*Créez un namespace ``hw`` (ou ce que vous voulez) pour tout l'exercice.*

## Deployment

### Description Yaml

Dans le repo ``k8s-101/k8s``, ouvrir ``deployment.yaml``.

*Expliquez la structure de la ressource.*

Si vous avez accès à un registry (public, c'est plus simple), vous pouvez y poussez votre image docker,
et la renseigner dans ce yaml.

Pour créer la ressource dans le namespace, depuis la racine du repo
```bash
kubectl -n hw apply -f k8s/deployment.yaml
```

Récupérez le déploiement effectif
```bash
kubectl -n get deploy/myapp -o yaml | less
```

*Comment est récupérée l'image docker ?*

*Comment se passe une rolling update ?*

*Que se passe-t-il si le pod crash ? Simulez le crash.*

### Interaction avec un pod

Dans un 2eme shell sur la vm, vous pouvez observer la construction de la ressource
```bash
watch sudo kubectl -n hw get all
```

On peut lire les logs du pod
```bash
kubectl -n hw logs nom-du-pod
```

On peut (quand l'image le permet) exécuter une commande dans le container du pod, e.g., un shell
```bash
kubectl -n hw exec -it nom-du-pod sh
wget -q -O - localhost:8080
```

Le pod reste inaccessible pour l'instant depuis le host (la vm). On peut forwarder un port du host vers un port du pod.
Dans un premier terminal
```bash
kubectl -n hw port-forward pods/nom-du-pod 8081:8080
```

Et, par exemple, dans un autre terminal (tjs dans la VM)
```bash
curl localhost:8081/version
```


### Scaling

On peut modifier le nombre de replicas du deployment directement
```bash
kubectl -n hw scale --replicas=2 deploy/myapp
```

On peut aussi le faire en "infra as code" (c'est mieux en général), i.e., en modifiant directement le yaml, puis
```bash
kubectl -n hw apply -f k8s/deployment.yaml
```

### Montée de version

Idem, on peut modifier l'image directement
```bash
kubectl -n hw set image deploy/myapp myapp=pevablanchard/k8s-101:2.0
```
Ou bien, et c'est mieux, modifier le yaml et ``apply``.

*Observez avec un ``watch`` le rolling update.*
*Vérifiez la version sur le endpoint correspondant.*

Exécutez
```bash
kubectl help rollout
```
*Utiliser un rollout pour revenir en version 1.0*




## Service

*Décrire la structure de la ressource ``service.yaml``*
*Créer la ressource*

Depuis un pod busybox dans le même namespace, exécutez
```bash
ping myapp-svc
ping myapp-svc.hw
ping myapp-svc.hw.svc.cluster.local
```
Ctrl+C pour terminer le process s'il ne répond pas.

*À quoi correspond cette ip ?*

Toujours depuis busybox
```bash
wget -q -O - myapp-svc:8080/version
```

Dans un autre terminal, remettez l'image ``pevablanchard/k8s-101:1.0`` sur le déploiement ``myapp``,
et dans le busybox
```bash
watch -n 1 wget -q -O "-" myapp-svc:8080/version
```
Avec un peu de chance, on peut voir une oscillation dans la version.

*Pourquoi ?*

## Configuration d'un pod

*Expliquez la structure du ``configmap.yaml``. Créez la ressource dans le namespace ``hw``.*

*Idem pour ``deployment-with-config.yaml``*

Testez en appelant, par l'une des méthodes vues ci-dessus, le endpoint ``/`` du conteneur.

## Readiness et liveness probes

*Déployez la ressource ``deployment-with-probes.yaml``. Que se passe-t-il ? Pourquoi ? Fixez.*

## Secret

*Expliquez la structure du ``deployment-with-secret.yaml``.*

Cela ressemble à une configmap. Cependant, il faut éviter de mettre une ressource ``secret.yaml`` dans le repo git.
Le provisioning d'un secret dans un namespace est toute une histoire (cf. les SealedSecret).
Ici, on peut se contenter d'en créer un depuis le host à partir d'un fichier
```bash
echo "Batman" > name
kubectl -n hw create secret generic --from-file=name myapp-secret
```

*Inspectez le yaml effectif du secret. Pourquoi ne lit-on pas "Batman" ?*

*Créez la ressource ``deployment-with-secret.yaml``. Testez.*

## Side car

*Créez la ressource ``deployment-with-side-car.yaml``. Que se passe-t-il ?*

Pour exécuter une commande, e.g. ouvrir un shell ``sh``, sur un container spécifique du pod:
```bash
kubectl -n hw exec -it nom-du-pod -c nom-du-container sh
```

Depuis le sidecar, exécutez
```bash
wget -q -O - localhost:8080
nc -l -p 8080
```
La deuxième instruction essaie d'ouvrir le port 8080 en écoute. *Pourquoi échoue-t-elle ?*


## Cleaning

Supprimez toutes les ressources du namespace ``hw``.